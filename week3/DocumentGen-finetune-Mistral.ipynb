{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6a2da0-a246-4c35-bd33-535d1ce124e7",
   "metadata": {},
   "source": [
    "# Fine-tuning Mistral with LoRA for Technical Documentation Generation\n",
    "\n",
    "This notebook demonstrates how to fine-tune the Mistral-7B language model for generating technical documentation using Low-Rank Adaptation (LoRA). The process involves collecting documentation from popular open-source repositories, preparing the data, and training the model efficiently.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- CUDA-compatible GPU with sufficient VRAM (at least 8GB recommended)\n",
    "- Hugging Face account and API token\n",
    "- Git installed on your system\n",
    "\n",
    "### Required Libraries\n",
    "```bash\n",
    "pip install transformers bitsandbytes datasets peft gitpython huggingface_hub\n",
    "pip install --upgrade peft\n",
    "pip install --upgrade accelerate\n",
    "pip install git+https://github.com/huggingface/peft.git\n",
    "```\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Model Loading and Quantization** (Cells 1-3)\n",
    "   - Sets up necessary libraries\n",
    "   - Loads Mistral-7B model with 4-bit quantization\n",
    "   - Configures the tokenizer\n",
    "\n",
    "2. **LoRA Configuration** (Cell 4)\n",
    "   - Implements LoRA for efficient fine-tuning\n",
    "   - Patches model components for device compatibility\n",
    "   - Prepares trainable parameters\n",
    "\n",
    "3. **Data Collection and Processing** (Cell 5)\n",
    "   - Clones technical documentation repositories:\n",
    "     - PyTorch\n",
    "     - TensorFlow\n",
    "     - scikit-learn\n",
    "     - pandas\n",
    "   - Processes Markdown files\n",
    "   - Cleans and formats the documentation\n",
    "\n",
    "4. **Dataset Preparation** (Cell 6)\n",
    "   - Tokenizes the collected documents\n",
    "   - Creates train/evaluation splits\n",
    "   - Prepares data collator for language modeling\n",
    "\n",
    "5. **Model Fine-tuning** (Cell 7)\n",
    "   - Configures training arguments:\n",
    "     - 3 epochs\n",
    "     - Learning rate: 2e-4\n",
    "     - Batch size: 4\n",
    "     - Mixed-precision training (fp16)\n",
    "   - Initializes trainer and starts training\n",
    "\n",
    "6. **Model Evaluation** (Cell 8)\n",
    "   - Compares base and fine-tuned models\n",
    "   - Generates sample technical documentation\n",
    "   - Analyzes output quality\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Uses 4-bit quantization for reduced memory usage\n",
    "- Implements LoRA for efficient parameter updates\n",
    "- Processes real-world technical documentation\n",
    "- Includes proper error handling and device management\n",
    "- Provides comparison between base and fine-tuned outputs\n",
    "\n",
    "## Usage Notes\n",
    "\n",
    "1. Replace `my_token` with your Hugging Face API token\n",
    "2. Adjust batch sizes and model parameters based on your GPU memory\n",
    "3. Modify the list of GitHub repositories as needed\n",
    "4. Consider increasing epochs for better results\n",
    "5. Monitor training loss for convergence\n",
    "\n",
    "## Performance Considerations\n",
    "\n",
    "- 4-bit quantization significantly reduces memory requirements\n",
    "- LoRA minimizes the number of trainable parameters\n",
    "- Training time depends on:\n",
    "  - GPU capabilities\n",
    "  - Dataset size\n",
    "  - Number of epochs\n",
    "  - Batch size\n",
    "\n",
    "## Customization\n",
    "\n",
    "You can customize the training by:\n",
    "- Adding more documentation sources\n",
    "- Adjusting LoRA parameters (r, alpha, target modules)\n",
    "- Modifying training hyperparameters\n",
    "- Implementing different data cleaning strategies\n",
    "- Adding domain-specific preprocessing steps\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "Common issues and solutions:\n",
    "1. Out of Memory (OOM):\n",
    "   - Reduce batch size\n",
    "   - Increase quantization\n",
    "   - Reduce model size\n",
    "\n",
    "2. Training Instability:\n",
    "   - Adjust learning rate\n",
    "   - Modify LoRA configuration\n",
    "   - Check data quality\n",
    "\n",
    "3. Poor Generation Quality:\n",
    "   - Increase training data\n",
    "   - Adjust temperature and sampling parameters\n",
    "   - Fine-tune for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1041ba2-837e-41d9-95fb-9d40926f6d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (4.44.0)\n",
      "Requirement already satisfied: bitsandbytes in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.45.1)\n",
      "Requirement already satisfied: datasets in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: peft in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.14.1.dev0)\n",
      "Requirement already satisfied: gitpython in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (3.1.44)\n",
      "Requirement already satisfied: huggingface_hub in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: torch~=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (1.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from gitpython) (4.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (1.13.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.0->bitsandbytes) (12.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch~=2.0->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy->torch~=2.0->bitsandbytes) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: peft in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (0.14.1.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (2.4.0)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (4.44.0)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (1.3.0)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (0.4.4)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft) (0.28.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.20)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from accelerate) (0.4.4)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-6cuklxjn\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-6cuklxjn\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 2825774d2de1c8bd0604ac685867edd79d608a9e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (24.1)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (2.4.0)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (4.44.0)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (1.3.0)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (0.4.4)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from peft==0.14.1.dev0) (0.28.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2024.6.1)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (1.13.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.14.1.dev0) (12.6.20)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft==0.14.1.dev0) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from transformers->peft==0.14.1.dev0) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.14.1.dev0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.14.1.dev0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# %% Setup: Install necessary libraries (if not already installed)\n",
    "!pip install transformers bitsandbytes datasets peft gitpython huggingface_hub\n",
    "!pip install --upgrade peft\n",
    "!pip install --upgrade accelerate\n",
    "!pip install git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b78327c-6e7d-408c-b997-46378fb08ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import libraries\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Monkey-patch the `.to()` method of PreTrainedModel to be a no-op.\n",
    "# This prevents Accelerate from calling .to() on the 4-bit model.\n",
    "from transformers import PreTrainedModel\n",
    "PreTrainedModel.to = lambda self, *args, **kwargs: self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3377337-706b-4aca-aaa3-0996c58c599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b69cea4db24a88a18601ac02ff21fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Load and Quantize the Base Mistral Model\n",
    "#\n",
    "# We load the Mistral model (here we use the \"mistralai/mistral-7b-v0.1\" model)\n",
    "# in 4‑bit mode using BitsAndBytes. The model is loaded with our Hugging Face token.\n",
    "#\n",
    "# **Note:** Replace the token and model identifier as needed.\n",
    "\n",
    "# %% Load the Mistral model and tokenizer with 4-bit quantization\n",
    "model_name = \"mistralai/mistral-7b-v0.1\"  # Change if needed\n",
    "my_token = \"\"  # Replace with your actual token\n",
    "\n",
    "# Define the 4-bit quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "# Load the tokenizer and set its pad token (we use the EOS token as the pad token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load the model in 4-bit mode.\n",
    "# We do not pass device_map=\"auto\" to avoid Accelerate dispatch (which calls .to()).\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    use_auth_token=my_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58e46e0-e6d4-4d39-98bb-c8ebc9cf3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the base model for later reference\n",
    "import copy\n",
    "base_model_copy = copy.deepcopy(model)\n",
    "\n",
    "# (Apply your LoRA fine-tuning steps here)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Patch MistralRotaryEmbedding to fix device issues in rotary embeddings.\n",
    "from transformers.models.mistral.modeling_mistral import MistralRotaryEmbedding\n",
    "\n",
    "# Save the original forward method\n",
    "original_forward = MistralRotaryEmbedding.forward\n",
    "\n",
    "def patched_forward(self, x, position_ids):\n",
    "    # Get the device from input x.\n",
    "    device = x.device\n",
    "    # If the internal inverse frequency tensor exists, move it to the same device.\n",
    "    if hasattr(self, \"inv_freq\"):\n",
    "        self.inv_freq = self.inv_freq.to(device)\n",
    "    # Also ensure that position_ids are moved to the device.\n",
    "    position_ids = position_ids.to(device)\n",
    "    # Call the original forward method.\n",
    "    return original_forward(self, x, position_ids)\n",
    "\n",
    "# Override the forward method with our patched version.\n",
    "MistralRotaryEmbedding.forward = patched_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752566a9-cb23-42d5-88f9-0ffa269212a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA parameters prepared. Number of trainable parameters: 6815744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Prepare the Model for Efficient Fine-Tuning using LoRA\n",
    "#\n",
    "# We use PEFT’s LoRA to fine-tune only a small subset of parameters.\n",
    "# The target modules (\"q_proj\" and \"v_proj\") may be adjusted based on the model's implementation.\n",
    "\n",
    "# %% Prepare the model for LoRA fine-tuning\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Adjust if necessary\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"LoRA parameters prepared. Number of trainable parameters:\",\n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da0ae77-d657-4ac0-90ec-8d014df4d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning repository https://github.com/pytorch/pytorch.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating files: 100% (18367/18367), done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 markdown files in pytorch.\n",
      "Repository tensorflow_docs already cloned.\n",
      "Found 112 markdown files in tensorflow_docs.\n",
      "Cloning repository https://github.com/scikit-learn/scikit-learn.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'scikit-learn'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 markdown files in scikit-learn.\n",
      "Cloning repository https://github.com/pandas-dev/pandas.git ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pandas'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 markdown files in pandas.\n",
      "\n",
      "Total collected and cleaned markdown documents: 117\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Data Collection, Cleansing, and Transformation\n",
    "#\n",
    "# We collect technical documentation from two GitHub repositories:\n",
    "# - PyTorch (docs in the `docs/` folder)\n",
    "# - TensorFlow Docs (markdown files at the root and subdirectories)\n",
    "\n",
    "# %% Define GitHub repositories to clone and process\n",
    "github_repos = [\n",
    "    {\"name\": \"pytorch\", \"url\": \"https://github.com/pytorch/pytorch.git\", \"docs_path\": \"docs\"},\n",
    "    {\"name\": \"tensorflow_docs\", \"url\": \"https://github.com/tensorflow/docs.git\", \"docs_path\": \"\"},\n",
    "    {\"name\": \"scikit-learn\", \"url\": \"https://github.com/scikit-learn/scikit-learn.git\", \"docs_path\": \"doc\"},\n",
    "    {\"name\": \"pandas\", \"url\": \"https://github.com/pandas-dev/pandas.git\", \"docs_path\": \"doc\"},\n",
    "    # Add more repositories as needed...\n",
    "]\n",
    "\n",
    "data_texts = []\n",
    "\n",
    "for repo in github_repos:\n",
    "    repo_dir = repo[\"name\"]\n",
    "    if not os.path.exists(repo_dir):\n",
    "        print(f\"Cloning repository {repo['url']} ...\")\n",
    "        os.system(f\"git clone {repo['url']} {repo_dir}\")\n",
    "    else:\n",
    "        print(f\"Repository {repo['name']} already cloned.\")\n",
    "\n",
    "    # Use the docs_path if provided; otherwise search the repo root.\n",
    "    search_dir = os.path.join(repo_dir, repo[\"docs_path\"]) if repo[\"docs_path\"] else repo_dir\n",
    "\n",
    "    # Recursively find Markdown files (*.md)\n",
    "    md_files = glob.glob(os.path.join(search_dir, \"**/*.md\"), recursive=True)\n",
    "    print(f\"Found {len(md_files)} markdown files in {repo['name']}.\")\n",
    "\n",
    "    for file_path in md_files:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                # Remove code blocks (content between triple backticks)\n",
    "                text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)\n",
    "                # Remove extra whitespace\n",
    "                text = re.sub(r'\\s+', ' ', text)\n",
    "                data_texts.append(text.strip())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal collected and cleaned markdown documents: {len(data_texts)}\")\n",
    "\n",
    "# %% Create a Dataset from the collected texts\n",
    "df = pd.DataFrame({\"text\": data_texts})\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05893174-08c3-4d49-9521-5de4deb1abf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768a633c8cb94a66b5066f4beabfd52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n",
      "Train/evaluation split complete.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Tokenization and Dataset Preparation\n",
    "#\n",
    "# We tokenize the documents, truncating them to 512 tokens.\n",
    "# (For larger documents, consider using a sliding window approach.)\n",
    "\n",
    "# %% Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "print(\"Tokenization complete.\")\n",
    "\n",
    "# Split the dataset into train (90%) and evaluation (10%) sets.\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "print(\"Train/evaluation split complete.\")\n",
    "\n",
    "# Create a data collator for causal language modeling (no masking).\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f2cf50-c7ed-4575-a85b-537fb766257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [81/81 01:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.480753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.486300</td>\n",
       "      <td>1.469751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.486300</td>\n",
       "      <td>1.488375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=81, training_loss=1.4175228071801456, metrics={'train_runtime': 92.6311, 'train_samples_per_second': 3.401, 'train_steps_per_second': 0.874, 'total_flos': 6852848088268800.0, 'train_loss': 1.4175228071801456, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Fine-Tuning the Model\n",
    "#\n",
    "# We define training arguments and initialize the Hugging Face Trainer.\n",
    "\n",
    "# %% Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mistral_finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Mixed-precision training (CUDA environment)\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# %% Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# %% Start fine-tuning\n",
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da78b3d-3449-4cad-89eb-3e1c314414b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98af90f4ee643628a3ecde483b0fb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Base Model Output ###\n",
      "\n",
      "Generate detailed technical documentation for a Python function that implements a 2D convolution operation for image processing.\n",
      "    \n",
      "The documentation should include:\n",
      "- **Problem Statement:** A clear description of the purpose of the function.\n",
      "- **Algorithm Explanation:** A detailed explanation of how the 2D convolution is performed, including discussion on kernel size, padding, stride, and edge handling.\n",
      "- **Input/Output Specifications:** Information on the expected types and shapes of inputs (e.g., image matrices, kernel arrays) and the output.\n",
      "- **Code Examples:** Illustrative code examples that include comments explaining each part of the code.\n",
      "- **Performance Analysis:** A brief discussion on the computational complexity and any optimization considerations.\n",
      "\n",
      "Provide the answer in markdown format with proper sections and code blocks.\n",
      "\n",
      "## The Code:\n",
      "\n",
      "```python\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def conv2d(input_image, kernel):\n",
      "    # Preprocessing steps\n",
      "    padded_input = np.pad(input_image, ((1, 1), (1, 1), (0, 0)), mode='constant', constant_values=0)\n",
      "    input_height, input_width, input_channels = padded_input.shape\n",
      "    kernel_height, kernel_width, _ = kernel.shape\n",
      "    output_height = (input_height - kernel_height + 1)\n",
      "    output_width = (input_width - kernel_width + 1)\n",
      "    output_channels = input_channels\n",
      "\n",
      "    # Convolution operation\n",
      "    output = np.zeros((output_height, output_width, output_channels))\n",
      "    for y in range(output_height):\n",
      "       \n",
      "\n",
      "### Fine-Tuned Model Output ###\n",
      "\n",
      "Generate detailed technical documentation for a Python function that implements a 2D convolution operation for image processing.\n",
      "    \n",
      "The documentation should include:\n",
      "- **Problem Statement:** A clear description of the purpose of the function.\n",
      "- **Algorithm Explanation:** A detailed explanation of how the 2D convolution is performed, including discussion on kernel size, padding, stride, and edge handling.\n",
      "- **Input/Output Specifications:** Information on the expected types and shapes of inputs (e.g., image matrices, kernel arrays) and the output.\n",
      "- **Code Examples:** Illustrative code examples that include comments explaining each part of the code.\n",
      "- **Performance Analysis:** A brief discussion on the computational complexity and any optimization considerations.\n",
      "\n",
      "Provide the answer in markdown format with proper sections and code blocks. Be sure to refer to any relevant resources or documentation you used during the process.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Evaluation: Comparing the Fine-Tuned Model with the Base Model\n",
    "#\n",
    "# We compare the outputs of the fine-tuned model and the base model on a technical documentation prompt.\n",
    "\n",
    "# %% Define a helper function to generate text from a prompt\n",
    "def generate_text(model, prompt, max_new_tokens=200):\n",
    "    # Get the device from the model's parameters.\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Tokenize the prompt.\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    # Move each tensor to the device.\n",
    "    inputs = {key: tensor.to(device) for key, tensor in inputs.items()}\n",
    "    \n",
    "    # Generate text using the model.\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    # Decode and return the generated tokens.\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "prompt = (\n",
    "    \"\"\"Generate detailed technical documentation for a Python function that implements a 2D convolution operation for image processing.\n",
    "    \n",
    "The documentation should include:\n",
    "- **Problem Statement:** A clear description of the purpose of the function.\n",
    "- **Algorithm Explanation:** A detailed explanation of how the 2D convolution is performed, including discussion on kernel size, padding, stride, and edge handling.\n",
    "- **Input/Output Specifications:** Information on the expected types and shapes of inputs (e.g., image matrices, kernel arrays) and the output.\n",
    "- **Code Examples:** Illustrative code examples that include comments explaining each part of the code.\n",
    "- **Performance Analysis:** A brief discussion on the computational complexity and any optimization considerations.\n",
    "\n",
    "Provide the answer in markdown format with proper sections and code blocks.\"\"\"\n",
    ")\n",
    "# Load the base model (without fine-tuning adaptations) for comparison.\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    use_auth_token=my_token\n",
    ")\n",
    "\n",
    "print(\"### Base Model Output ###\\n\")\n",
    "print(generate_text(base_model, prompt))\n",
    "\n",
    "print(\"\\n### Fine-Tuned Model Output ###\\n\")\n",
    "print(generate_text(model, prompt))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Conclusion\n",
    "#\n",
    "# In this notebook, we:\n",
    "# - Loaded a Mistral model in 4‑bit mode using BitsAndBytes on a CUDA environment.\n",
    "# - Prepared the model for efficient fine‑tuning using LoRA.\n",
    "# - Collected and cleaned technical documentation data from GitHub.\n",
    "# - Tokenized and prepared a dataset.\n",
    "# - Fine-tuned the model on the collected data.\n",
    "# - Compared the outputs from the fine-tuned model and the original base model.\n",
    "#\n",
    "# Experiment further with additional repositories, data cleansing methods, and hyperparameter settings to tailor the model to your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea727b-70c5-4ef0-9a9d-541837ba51ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

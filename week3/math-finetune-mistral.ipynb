{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b60082-220d-4e16-b269-3b55571d5381",
   "metadata": {},
   "source": [
    "# Fine-tuning Mistral for Mathematical Problem Solving\n",
    "\n",
    "This notebook demonstrates how to fine-tune the Mistral-7B language model specifically for solving mathematical word problems using the GSM8K dataset. The implementation uses quantization and Low-Rank Adaptation (LoRA) for efficient training.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- CUDA-compatible GPU (16GB+ VRAM recommended)\n",
    "- Hugging Face account with access to Mistral-7B\n",
    "- Git installed on your system\n",
    "\n",
    "### Required Libraries\n",
    "```bash\n",
    "pip install -q transformers datasets accelerate bitsandbytes wandb py7zr\n",
    "pip install -q peft trl huggingface_hub\n",
    "```\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- 4-bit quantization for reduced memory usage\n",
    "- LoRA fine-tuning for efficient parameter updates\n",
    "- Step-by-step problem solving approach\n",
    "- Comparison between base and fine-tuned model outputs\n",
    "- GSM8K dataset integration\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Setup and Dependencies** (Initial Setup)\n",
    "   - Library installations\n",
    "   - Basic configurations\n",
    "   - GPU optimizations\n",
    "   - Authentication setup\n",
    "\n",
    "2. **Model Configuration** (Test Cases & Model Loading)\n",
    "   - Test case definitions\n",
    "   - Model and tokenizer initialization\n",
    "   - 4-bit quantization setup\n",
    "   - Token handling\n",
    "\n",
    "3. **Dataset Processing** (GSM8K Integration)\n",
    "   - Loading GSM8K dataset\n",
    "   - Data formatting and preprocessing\n",
    "   - Problem template structuring\n",
    "   - Tokenization setup\n",
    "\n",
    "4. **Training Configuration** (LoRA Setup)\n",
    "   - LoRA parameters configuration\n",
    "   - Training arguments setup\n",
    "   - Batch size and learning rate settings\n",
    "   - Gradient accumulation configuration\n",
    "\n",
    "5. **Training Process** (Model Fine-tuning)\n",
    "   - Dataset preparation\n",
    "   - Model training initialization\n",
    "   - Progress tracking\n",
    "   - Model saving functionality\n",
    "\n",
    "6. **Evaluation** (Model Comparison)\n",
    "   - Base model vs. fine-tuned model comparison\n",
    "   - Test case execution\n",
    "   - Solution generation\n",
    "   - Performance analysis\n",
    "\n",
    "## Usage Guide\n",
    "\n",
    "1. **Initial Setup**\n",
    "   - Set your Hugging Face token\n",
    "   - Configure environment variables\n",
    "   - Verify model access\n",
    "\n",
    "2. **Dataset Configuration**\n",
    "   - Default: 1000 training examples, 100 test examples\n",
    "   - Customizable dataset size\n",
    "   - Structured problem format\n",
    "\n",
    "3. **Training Parameters**\n",
    "   - Epochs: 3\n",
    "   - Batch size: 4\n",
    "   - Gradient accumulation steps: 16\n",
    "   - Learning rate: 2e-5\n",
    "   - FP16 training enabled\n",
    "\n",
    "4. **Model Customization**\n",
    "   - Adjustable LoRA parameters (r=32, alpha=64)\n",
    "   - Configurable target modules\n",
    "   - Customizable dropout rate\n",
    "   - Solution generation parameters\n",
    "\n",
    "## Performance Optimization\n",
    "\n",
    "- Uses torch.cuda optimizations\n",
    "- Implements gradient checkpointing\n",
    "- Employs mixed-precision training\n",
    "- Utilizes efficient tokenization\n",
    "\n",
    "## Test Cases\n",
    "\n",
    "The notebook includes diverse test cases:\n",
    "1. Factory production and profit calculation\n",
    "2. Fundraising and commission problems\n",
    "3. Comparative rate problems\n",
    "4. Compound interest calculations\n",
    "\n",
    "## Customization Options\n",
    "\n",
    "You can customize:\n",
    "- Dataset size and composition\n",
    "- Training parameters\n",
    "- Model architecture settings\n",
    "- Test case scenarios\n",
    "- Output formatting\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "Common issues and solutions:\n",
    "1. Memory Management:\n",
    "   - Adjust batch size\n",
    "   - Modify gradient accumulation\n",
    "   - Fine-tune quantization settings\n",
    "\n",
    "2. Training Stability:\n",
    "   - Adjust learning rate\n",
    "   - Modify LoRA parameters\n",
    "   - Check dataset quality\n",
    "\n",
    "3. Output Quality:\n",
    "   - Adjust generation parameters\n",
    "   - Modify problem templates\n",
    "   - Increase training data\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. Data Preparation:\n",
    "   - Use consistent formatting\n",
    "   - Include diverse problem types\n",
    "   - Ensure clean data\n",
    "\n",
    "2. Training:\n",
    "   - Monitor loss curves\n",
    "   - Save checkpoints\n",
    "   - Validate outputs regularly\n",
    "\n",
    "3. Evaluation:\n",
    "   - Use diverse test cases\n",
    "   - Compare with base model\n",
    "   - Analyze step-by-step solutions\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Model saves after each epoch\n",
    "- Evaluation occurs per epoch\n",
    "- Solutions include detailed steps\n",
    "- Outputs are deterministic (can be made stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9b3cce-682d-4b6f-a8cf-ec0a81e6b84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mPlease enter your HuggingFace token (from https://huggingface.co/settings/tokens)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your HuggingFace token:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully authenticated and verified model access!\n",
      "Loading base model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a703e621addf48b18f21970ceffb29af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating solutions with base model...\n",
      "\n",
      "Test Case 1:\n",
      "Problem: A factory produces widgets at a rate of 800 per hour. Due to quality control, 5% of widgets are rejected. \n",
      "    The factory operates 2 shifts per day, each shift being 8 hours long. If the factory sells each good widget for $12.50, \n",
      "    and the daily operating cost is $45,000, what is the daily profit?\n",
      "Solution: ### Problem: A factory produces widgets at a rate of 800 per hour. Due to quality control, 5% of widgets are rejected. \n",
      "    The factory operates 2 shifts per day, each shift being 8 hours long. If the factory sells each good widget for $12.50, \n",
      "    and the daily operating cost is $45,000, what is the daily profit?\n",
      "### Let's solve this step by step:\n",
      "1. Write the formula for the number of widgets produced per shift.\n",
      "    Let $P$ be the number of widgets produced per shift.\n",
      "    $P = 800$\n",
      "2. Write the formula for the number of widgets rejected per shift.\n",
      "    Let $R$ be the number of widgets rejected per shift.\n",
      "    $R = 5\\%$ of $P$ (or $0.05P$)\n",
      "    $R = 0.05P$\n",
      "3. Write the formula for the number of widgets produced per day.\n",
      "    Let $D$ be the number of widgets produced per day.\n",
      "    $D = 2\\cdot P$\n",
      "4. Write the formula for the number of widgets sold per day.\n",
      "    Let $S$ be the number of widgets sold per day.\n",
      "    $S = D - R$\n",
      "5. Write the formula for the daily revenue.\n",
      "    Let $R$ be the daily revenue.\n",
      "    $R = $Selling price per widget $\\cdot$ Number of widgets sold per day\n",
      "    $R = $12.50$\\cdot S$\n",
      "6. Write the formula for the daily operating cost.\n",
      "    Let $C$ be the daily operating cost.\n",
      "    $C = $50,000$\n",
      "7. Write the formula for the daily profit.\n",
      "    Let $P$ be the daily profit.\n",
      "    $P = $Daily revenue $-$ Daily operating cost\n",
      "    $P = R - C$\n",
      "8. Substitute values into the formula for the daily profit.\n",
      "    $P = $12.50$\\cdot S -$50,000\n",
      "    $P = $12.50$(2$\\cdot$ 800 - 0.05$\\cdot$ 2$\\cdot$ 800)\n",
      "\n",
      "Test Case 2:\n",
      "Problem: In a school fundraiser, students sell chocolate bars. Each student receives a 20% commission on their sales. \n",
      "    If a chocolate bar costs $5, and the school needs to raise $10,000, and there are 45 students participating, \n",
      "    how many chocolate bars does each student need to sell on average to reach the goal?\n",
      "Solution: ### Problem: In a school fundraiser, students sell chocolate bars. Each student receives a 20% commission on their sales. \n",
      "    If a chocolate bar costs $5, and the school needs to raise $10,000, and there are 45 students participating, \n",
      "    how many chocolate bars does each student need to sell on average to reach the goal?\n",
      "### Let's solve this step by step:\n",
      "\n",
      "### Step 1:\n",
      "\n",
      "Create the following variables:\n",
      "\n",
      "**$5** = chocolatePrice\n",
      "**$10,000** = goal\n",
      "**45** = numStudents\n",
      "\n",
      "### Step 2:\n",
      "\n",
      "Formulate the problem in terms of variables\n",
      "\n",
      "\"the student receives a 20% commission on their sales\"\n",
      "\n",
      "$5 * 20% = 5% of the chocolate cost.\n",
      "\n",
      "So, $5 * 5% = $0.25\n",
      "\n",
      "\"the school needs to raise $10,000\"\n",
      "\n",
      "$10,000 / 0.25 = $40,000\n",
      "\n",
      "### Step 3:\n",
      "\n",
      "Solve the problem using the variables\n",
      "\n",
      "$40,000 / numStudents = x\n",
      "\n",
      "$40,000 / 45 = x\n",
      "\n",
      "x = $900.00\n",
      "\n",
      "### Step 4:\n",
      "\n",
      "Formulate the answer in terms of variables\n",
      "\n",
      "$900.00 = x\n",
      "\n",
      "$5 * x = 5 * 900\n",
      "\n",
      "$5 * 900 = $4500\n",
      "\n",
      "### Step 5:\n",
      "\n",
      "Solve the problem using the variables\n",
      "\n",
      "$4500 / chocolatePrice = x\n",
      "\n",
      "$4500 / $5 = x\n",
      "\n",
      "x = 900\n",
      "\n",
      "### Step 6:\n",
      "\n",
      "Formulate the answer in terms of variables\n",
      "\n",
      "900 = x\n",
      "\n",
      "900 chocolate bars = x\n",
      "\n",
      "### Step 7:\n",
      "\n",
      "Solve the problem using the variables\n",
      "\n",
      "x = 900\n",
      "\n",
      "x = 900\n",
      "\n",
      "### Step 8:\n",
      "\n",
      "Formulate the answer in terms of variables\n",
      "\n",
      "900 = x\n",
      "\n",
      "900 chocolate bars = x\n",
      "\n",
      "### Step 9:\n",
      "\n",
      "\n",
      "Now loading and preparing math dataset...\n",
      "\n",
      "Preparing model for training...\n",
      "trainable params: 83,886,080 || all params: 7,325,618,176 || trainable%: 1.1451\n",
      "\n",
      "Setting up training arguments...\n",
      "\n",
      "Initializing trainer...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 43:25, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.692600</td>\n",
       "      <td>1.502407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.189700</td>\n",
       "      <td>1.088021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.127900</td>\n",
       "      <td>1.009423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete! Saving model...\n",
      "\n",
      "Loading fine-tuned model for comparison...\n",
      "\n",
      "Comparing solutions between base and fine-tuned models...\n",
      "\n",
      "=== Model Solution Comparison ===\n",
      "\n",
      "\n",
      "Test Case 1:\n",
      "\n",
      "Problem:\n",
      "A factory produces widgets at a rate of 800 per hour. Due to quality control, 5% of widgets are rejected. \n",
      "    The factory operates 2 shifts per day, each shift being 8 hours long. If the factory sells each good widget for $12.50, \n",
      "    and the daily operating cost is $45,000, what is the daily profit?\n",
      "\n",
      "Base Model Solution:\n",
      "### Problem: A factory produces widgets at a rate of 800 per hour. Due to quality control, 5% of widgets are rejected. \n",
      "    The factory operates 2 shifts per day, each shift being 8 hours long. If the factory sells each good widget for $12.50, \n",
      "    and the daily operating cost is $45,000, what is the daily profit?\n",
      "### Let's solve this step by step:\n",
      "### Step 1: Define variables\n",
      "### Step 2: Write equations\n",
      "### Step 3: Solve step-by-step\n",
      "### Step 4: Verify answer\n",
      "### Final answer: 1000000\n",
      "### Step by Step:\n",
      "### Step 1: Define variables\n",
      "### Step 2: Write equations\n",
      "### Step 3: Solve step-by-step\n",
      "### Step 4: Verify answer\n",
      "### Final answer: 1000000\n",
      "\n",
      "### Step by Step:\n",
      "    Step 1: Define variables\n",
      "    Step 2: Write equations\n",
      "    Step 3: Solve step-by-step\n",
      "    Step 4: Verify answer\n",
      "    Final answer: 1000000\n",
      "\n",
      "Fine-tuned Model Solution:\n",
      "### Problem: A factory produces widgets at a rate of 800 per hour. Due to quality control, 5% of widgets are rejected. \n",
      "    The factory operates 2 shifts per day, each shift being 8 hours long. If the factory sells each good widget for $12.50, \n",
      "    and the daily operating cost is $45,000, what is the daily profit?\n",
      "### Let's solve this step by step:\n",
      "### Step 1: Define Variables\n",
      "### Step 2: Write Equations\n",
      "### Step 3: Solve Step-by-Step\n",
      "### Step 4: Verify Answer\n",
      "### Final Answer: 1599.5\n",
      "\n",
      "### Step 1: Define Variables\n",
      "### Step 2: Write Equations\n",
      "### Step 3: Solve Step-by-Step\n",
      "### Step 4: Verify Answer\n",
      "### Final Answer: 1599.5\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test Case 2:\n",
      "\n",
      "Problem:\n",
      "In a school fundraiser, students sell chocolate bars. Each student receives a 20% commission on their sales. \n",
      "    If a chocolate bar costs $5, and the school needs to raise $10,000, and there are 45 students participating, \n",
      "    how many chocolate bars does each student need to sell on average to reach the goal?\n",
      "\n",
      "Base Model Solution:\n",
      "### Problem: In a school fundraiser, students sell chocolate bars. Each student receives a 20% commission on their sales. \n",
      "    If a chocolate bar costs $5, and the school needs to raise $10,000, and there are 45 students participating, \n",
      "    how many chocolate bars does each student need to sell on average to reach the goal?\n",
      "### Let's solve this step by step:\n",
      "### Step 1: Define Variables\n",
      "### Step 2: Write Equations\n",
      "### Step 3: Solve Step-by-Step\n",
      "### Step 4: Verify Answer\n",
      "### Final Answer: 25 chocolate bars.\n",
      "### Step 1: Define Variables\n",
      "### Step 2: Write Equations\n",
      "### Step 3: Solve Step-by-Step\n",
      "### Step 4: Verify Answer\n",
      "### Final Answer: 25 chocolate bars.\n",
      "\n",
      "Fine-tuned Model Solution:\n",
      "### Problem: In a school fundraiser, students sell chocolate bars. Each student receives a 20% commission on their sales. \n",
      "    If a chocolate bar costs $5, and the school needs to raise $10,000, and there are 45 students participating, \n",
      "    how many chocolate bars does each student need to sell on average to reach the goal?\n",
      "### Let's solve this step by step:\n",
      "### Step 1: Define Variables:\n",
      "    Let 'n' be the total number of chocolates sold by all students\n",
      "    Let 's' be the total number of students participating in the fundraiser\n",
      "    Let 'c' be the total cost of all chocolates sold\n",
      "### Step 2: Write Equations:\n",
      "    c = n*5\n",
      "    c = 10000\n",
      "    c = 20% of n\n",
      "### Step 3: Solve Step-by-Step:\n",
      "    Equation 1: c = n*5\n",
      "    Substitute 'c' = 10000 in Equation 1:\n",
      "    10000 = n*5\n",
      "    Divide both sides by 5:\n",
      "    2000 = n\n",
      "### Step 4: Verify Answer:\n",
      "   If n = 2000, then 20% of n = 10000\n",
      "    If n = 2000, then s = 45\n",
      "   Each student has to sell 2000 / 45 = 44.44 chocolates on average.\n",
      "### Final Answer: 44.44\n",
      "### Note: Round the answer to the nearest whole number.\n",
      "### Conclusion:\n",
      "    Each student needs to sell 44.44 chocolate bars, on average, to reach the fundraising goal.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test Case 3:\n",
      "\n",
      "Problem:\n",
      "A car rental company charges $45 per day plus $0.25 per mile. A competing company charges $35 per day plus \n",
      "    $0.45 per mile. At how many miles per day would the total cost be the same for both companies? Round to the nearest mile.\n",
      "\n",
      "Base Model Solution:\n",
      "### Problem: A car rental company charges $45 per day plus $0.25 per mile. A competing company charges $35 per day plus \n",
      "    $0.45 per mile. At how many miles per day would the total cost be the same for both companies? Round to the nearest mile.\n",
      "### Let's solve this step by step:\n",
      "    ### Step 1: Define Variables\n",
      "    ### Step 2: Write Equations\n",
      "    ### Step 3: Solve Step-by-Step\n",
      "    ### Step 4: Verify Answer\n",
      "    ### Step 5: Final Answer is 100.0 Miles per day\n",
      "\n",
      "Fine-tuned Model Solution:\n",
      "### Problem: A car rental company charges $45 per day plus $0.25 per mile. A competing company charges $35 per day plus \n",
      "    $0.45 per mile. At how many miles per day would the total cost be the same for both companies? Round to the nearest mile.\n",
      "### Let's solve this step by step:\n",
      "1. Find the total cost for the first company at 100 miles.\n",
      "2. Find the total cost for the second company at 100 miles.\n",
      "3. Subtract the total cost for the first company from the total cost for the second company.\n",
      "4. Solve for x.\n",
      "5. Round to the nearest mile.\n",
      "\n",
      "### Step 1: Find the total cost for the first company at 100 miles.\n",
      "    $45 \\times 1 + 0.25 \\times 100 = \\$50.50$\n",
      "### Step 2: Find the total cost for the second company at 100 miles.\n",
      "    $35 \\times 1 + 0.45 \\times 100 = \\$45.50$\n",
      "### Step 3: Subtract the total cost for the first company from the total cost for the second company.\n",
      "    $50.50 - 45.50 = \\$5.00$\n",
      "### Step 4: Solve for x.\n",
      "    $5.00 = 0.25 \\times x$\n",
      "    $5.00 \\div 0.25 = 20$\n",
      "### Step 5: Round to the nearest mile.\n",
      "    The car must be driven 20 miles per day to have the same total cost for both companies.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test Case 4:\n",
      "\n",
      "Problem:\n",
      "Jack is investing $10,000 with 6% annual compound interest. He wants to make periodic withdrawals to supplement \n",
      "    his income. If he withdraws $2,000 at the end of each year, how much money will be left in the account after 3 years?\n",
      "    Round to the nearest dollar.\n",
      "\n",
      "Base Model Solution:\n",
      "### Problem: Jack is investing $10,000 with 6% annual compound interest. He wants to make periodic withdrawals to supplement \n",
      "    his income. If he withdraws $2,000 at the end of each year, how much money will be left in the account after 3 years?\n",
      "    Round to the nearest dollar.\n",
      "### Let's solve this step by step:\n",
      "    Step 1: Define Variables\n",
      "    Step 2: Write Equations\n",
      "    Step 3: Solve Step-by-Step\n",
      "    Step 4: Verify Answer\n",
      "    Step 5: Final Answer is 7000\n",
      "\n",
      "### Final Answer:\n",
      "    The final answer is 8000.\n",
      "### Source:\n",
      "    [https://www.math-only-math.com/compound-interest-examples.html](https://www.math-only-math.com/compound-interest-examples.html)\n",
      "### Step 1: Define Variables\n",
      "    Step 1: Define Variables\n",
      "### Step 2: Write Equations\n",
      "    Step 2: Write Equations\n",
      "### Step 3: Solve Step-by-Step\n",
      "    Step 3: Solve Step-by-Step\n",
      "### Step 4: Verify Answer\n",
      "    Step 4: Verify Answer\n",
      "### Step 5: Final Answer is 7000\n",
      "    Step 5: Final Answer is 7000\n",
      "\n",
      "### Conclusion:\n",
      "    The final answer is 7000.\n",
      "\n",
      "Fine-tuned Model Solution:\n",
      "### Problem: Jack is investing $10,000 with 6% annual compound interest. He wants to make periodic withdrawals to supplement \n",
      "    his income. If he withdraws $2,000 at the end of each year, how much money will be left in the account after 3 years?\n",
      "    Round to the nearest dollar.\n",
      "### Let's solve this step by step:\n",
      "    ### Step 1: Define Variables\n",
      "    ### Step 2: Write Equations\n",
      "    ### Step 3: Solve Step-by-Step\n",
      "    ### Step 4: Verify Answer\n",
      "    ### Step 5: Final Answer is...\n",
      "\n",
      "### Final Answer is:\n",
      "\n",
      "### Step by Step:\n",
      "\n",
      "\n",
      "    ### Step 1: Define Variables\n",
      "    P = Principal amount of investment\n",
      "    r = annual compound interest rate\n",
      "    t = time in years\n",
      "    A = amount of money left in the account after t years\n",
      "    w = amount withdrawn annually\n",
      "    ### Step 2: Write Equations\n",
      "    A = P(1+r)^t - wt\n",
      "    ### Step 3: Solve Step-by-Step\n",
      "    P = 10,000\n",
      "    r = 6%\n",
      "    t = 3\n",
      "    w = 2,000\n",
      "    A = P(1+r)^t - wt\n",
      "    A = 10,000(1+0.06)^3 - 2,000 * 3\n",
      "    A = 12,024 - 6,000\n",
      "    A = 6,024\n",
      "    ### Step 4: Verify Answer\n",
      "    P = 10,000\n",
      "    r = 6%\n",
      "    t = 3\n",
      "    w = 2,000\n",
      "    A = 6,024\n",
      "    A = P(1+r)^t - wt\n",
      "    A = 10,000(1+0.06)^3 - 2,000 * 3\n",
      "    A = 12,024 - 6,000\n",
      "    A = 6,024\n",
      "    ### Step 5: Final Answer is...\n",
      "    The final answer is 6,024.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning LLMs: Math Problem Solving Demo\n",
    "# Section 1: Setup and Dependencies\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q transformers datasets accelerate bitsandbytes wandb py7zr\n",
    "!pip install -q peft trl huggingface_hub\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    PeftModel\n",
    ")\n",
    "from getpass import getpass\n",
    "from huggingface_hub import HfApi, login\n",
    "\n",
    "# Section 2: Hugging Face Authentication\n",
    "print(\"Please enter your HuggingFace token (from https://huggingface.co/settings/tokens)\")\n",
    "hf_token = getpass(\"Enter your HuggingFace token: \")\n",
    "\n",
    "# Set the token\n",
    "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = hf_token\n",
    "login(token=hf_token)  # This will authenticate your session\n",
    "\n",
    "# Optional: Set cache directory\n",
    "os.environ[\"HF_HOME\"] = \"/content/hf_home\"\n",
    "\n",
    "# Verify token and model access\n",
    "try:\n",
    "    api = HfApi()\n",
    "    api.model_info(\"mistralai/Mistral-7B-v0.1\")\n",
    "    print(\"‚úÖ Successfully authenticated and verified model access!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error: Unable to access the model. Please check your token and model permissions.\")\n",
    "    print(f\"Error details: {str(e)}\")\n",
    "    raise Exception(\"Model access verification failed\")\n",
    "\n",
    "# Section 3: Configuration and Test Cases\n",
    "# Enable CUDA optimizations\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "OUTPUT_DIR = \"math_tuned_model\"\n",
    "\n",
    "# Test cases for clear demonstration\n",
    "TEST_CASES = [\n",
    "    \"\"\"A factory produces widgets at a rate of 800 per hour. Due to quality control, 5% of widgets are rejected. \n",
    "    The factory operates 2 shifts per day, each shift being 8 hours long. If the factory sells each good widget for $12.50, \n",
    "    and the daily operating cost is $45,000, what is the daily profit?\"\"\",\n",
    "    \n",
    "    \"\"\"In a school fundraiser, students sell chocolate bars. Each student receives a 20% commission on their sales. \n",
    "    If a chocolate bar costs $5, and the school needs to raise $10,000, and there are 45 students participating, \n",
    "    how many chocolate bars does each student need to sell on average to reach the goal?\"\"\",\n",
    "    \n",
    "    \"\"\"A car rental company charges $45 per day plus $0.25 per mile. A competing company charges $35 per day plus \n",
    "    $0.45 per mile. At how many miles per day would the total cost be the same for both companies? Round to the nearest mile.\"\"\",\n",
    "    \n",
    "    \"\"\"Jack is investing $10,000 with 6% annual compound interest. He wants to make periodic withdrawals to supplement \n",
    "    his income. If he withdraws $2,000 at the end of each year, how much money will be left in the account after 3 years?\n",
    "    Round to the nearest dollar.\"\"\"\n",
    "]\n",
    "\n",
    "# Section 4: Dataset Loading and Model Functions\n",
    "def load_math_dataset():\n",
    "    \"\"\"Load and prepare the GSM8K dataset\"\"\"\n",
    "    dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "    \n",
    "    # Take a subset for demonstration\n",
    "    dataset = dataset.shuffle(seed=42)\n",
    "    dataset[\"train\"] = dataset[\"train\"].select(range(1000))\n",
    "    dataset[\"test\"] = dataset[\"test\"].select(range(100))\n",
    "    \n",
    "    def format_problem(example):\n",
    "        return {\n",
    "            \"text\": f\"\"\"### Problem: {example['question']}\n",
    "### Step 1: Define Variables\n",
    "### Step 2: Write Equations\n",
    "### Step 3: Solve Step-by-Step\n",
    "### Step 4: Verify Answer\n",
    "### Final Answer: \"\"\"\n",
    "    }\n",
    "    formatted_dataset = dataset.map(format_problem)\n",
    "    return formatted_dataset\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    \"\"\"Load the base model and tokenizer with 4-bit quantization\"\"\"\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        token=hf_token\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=hf_token)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def prepare_math_dataset(tokenizer, dataset):\n",
    "    \"\"\"Prepare math dataset for training\"\"\"\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=768,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = {}\n",
    "    for split in dataset.keys():\n",
    "        tokenized_dataset[split] = dataset[split].map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=dataset[split].column_names\n",
    "        )\n",
    "    \n",
    "    return tokenized_dataset\n",
    "\n",
    "def prepare_model_for_math_training(model):\n",
    "    \"\"\"Configure model with LoRA for math problem solving\"\"\"\n",
    "    lora_config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],  # Add more target modules\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "    \n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def setup_math_training_args():\n",
    "    \"\"\"Configure training arguments optimized for math problems\"\"\"\n",
    "    return TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=16,\n",
    "        learning_rate=2e-5,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"none\",\n",
    "        warmup_steps=100\n",
    "    )\n",
    "\n",
    "def generate_solution(model, tokenizer, problem):\n",
    "    \"\"\"Generate a solution using the model\"\"\"\n",
    "    prompt = f\"### Problem: {problem}\\n### Let's solve this step by step:\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=512,\n",
    "        temperature=0.7,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def demonstrate_comparison(base_model, fine_tuned_model, tokenizer, test_cases):\n",
    "    \"\"\"Compare solutions between base and fine-tuned models\"\"\"\n",
    "    print(\"\\n=== Model Solution Comparison ===\\n\")\n",
    "    \n",
    "    for i, problem in enumerate(test_cases, 1):\n",
    "        print(f\"\\nTest Case {i}:\\n\")\n",
    "        print(\"Problem:\")\n",
    "        print(problem)\n",
    "        \n",
    "        print(\"\\nBase Model Solution:\")\n",
    "        base_solution = generate_solution(base_model, tokenizer, problem)\n",
    "        print(base_solution)\n",
    "        \n",
    "        print(\"\\nFine-tuned Model Solution:\")\n",
    "        fine_tuned_solution = generate_solution(fine_tuned_model, tokenizer, problem)\n",
    "        print(fine_tuned_solution)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Section 5: Main Execution\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"Loading base model and tokenizer...\")\n",
    "    base_model, tokenizer = load_model_and_tokenizer()\n",
    "    \n",
    "    print(\"\\nGenerating solutions with base model...\")\n",
    "    for i, test_case in enumerate(TEST_CASES[:2], 1):\n",
    "        print(f\"\\nTest Case {i}:\")\n",
    "        print(\"Problem:\", test_case)\n",
    "        solution = generate_solution(base_model, tokenizer, test_case)\n",
    "        print(\"Solution:\", solution)\n",
    "    \n",
    "    print(\"\\nNow loading and preparing math dataset...\")\n",
    "    dataset = load_math_dataset()\n",
    "    tokenized_dataset = prepare_math_dataset(tokenizer, dataset)\n",
    "    \n",
    "    print(\"\\nPreparing model for training...\")\n",
    "    model = prepare_model_for_math_training(base_model)\n",
    "    \n",
    "    print(\"\\nSetting up training arguments...\")\n",
    "    training_args = setup_math_training_args()\n",
    "    \n",
    "    print(\"\\nInitializing trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nStarting training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\nTraining complete! Saving model...\")\n",
    "    trainer.save_model()\n",
    "    \n",
    "    print(\"\\nLoading fine-tuned model for comparison...\")\n",
    "    fine_tuned_model = PeftModel.from_pretrained(\n",
    "        base_model,\n",
    "        OUTPUT_DIR,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nComparing solutions between base and fine-tuned models...\")\n",
    "    demonstrate_comparison(base_model, fine_tuned_model, tokenizer, TEST_CASES)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fa4b7-1ea9-481c-b2e7-2ecb12c7431a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
